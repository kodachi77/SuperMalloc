Key insights:
\begin{enumerate}
 \item Often benchmarks are not good.  For example test-malloc\_test.c spins, and for large numbers of threads behavs badly.  Adding a sched\_yield can help (we add it if it spins for a long time.  Also mm\_pause can help, but we didn't do it here.)
 \item  Why does jemalloc sometimes stall for a long time?   Can I observe it?
 \item why do transactions fail (too big, conflicts with another thread, time slice interupts, page faults)?  We can avoid almost all of that for malloc.


 \item Virtual address space is cheap.  

 We can waste virtual address space.

 In fact, it's problematic to give back address space to some
 operating systems, since the search data structures are not always
 good.

 \item Per-CPU caching gives most of the value of Per-thread caching.

  No point in caching more than fits in L2 cache (L3 cache is shared.  Maybe L3 is worth it on a multi-socket machine), since we'll incur cache missues to use the data.  (See the rant about threadtest below: it doesn't touch the memory.)

 \item Measure the cost of per-cpu (which has synchronization) vs. per-thread (no synchronization, but it turns out that you must go through the thread variable) vs. global (expensive synchronization).

 \item RSS is very important for long-running applications.

 \item Hoard's benchmarks measure the wrong thing.
   \begin{enumerate}
   \item cache-scratch is wrong: it measures false sharing.  There's a
     fundamental tradeoff between minimizing the space allocated and
     avoiding false sharing.  We argue that the right decision here is
     to allow the programmer who is using malloc to make this
     decision.  (JE Malloc also agrees.  They say, if you don't want
     false sharing, ask for cache-aligned data.
     \cite{http://people.freebsd.org/~jasone/jemalloc/bsdcan2006/jemalloc.pdf})
   
  \item cache-thrash

  \item larson (not as tough as my server version)

  \item shbench

   \item threadtest is wrong: it doesn't touch the allocated memory.  (There's no point in caching more per thread than fits in cache)

  \item linux-scalability

   \end{enumerate}

  \item Jemalloc benchmarks
  \begin{enumuerate}
 \item malloc-test (we totally rule)
 \item super-smack
 \item cca
 \item cfrack
 \item gs
 \item sh6bench
 \item smlng
  \end{enumuerate}


 \item jemalloc has gone for fewer spacings over time.  We went with
   similar spacing.  There's one anomaly near 4K where we are only 2x
   space competitive, otherwise we are 25\% space competetive.

 \item jemalloc is going for more spacings out beyond 2MB to have less wastage in the virtual address space.  We stick to 2MB, but could do more.

 \item Explain how we keep track of the requested size (so we can estimate the footprint), but we still use 2^k sizes for huge.

 \item Need to measure each feature to justify it.
  \begin{itemize}
  \item small cache was helpful, but the global cache was a huge win (touching the global cache only once every 4MB is huge)
  \item large cache needed to avoid too many madvise calls.  (See the test-malloc\_test4K.data for the case with the cache).  Need to measure without any cache (that's the impact of all those system calls on madvise().
  \item huge system calls: we just do them.
  \end{itemize}

 \item compare tsx vs. no-tsx, compare to lockless, hoard, jemalloc, tcmalloc

 \item where should the paper go?  SPAA (due in Jan?), OSDI (due May?), Usenix ATC (July, due

 \item What is the value of a small thread-local cache? (We have data for that)

 \item Why do we need the caches?
  For small objects, we need the caches because they can be allocated and deallocated so fast, and we don't want all the thread contention.

  For large objects, we the cache is really of objects that are not purged.  (\url{http://lists.freebsd.org/pipermail/freebsd-arch/2012-October/013287.html} says 
\begin{quote}
MADV\_FREE is *way* nicer than MADV\_DONTNEED in the context of malloc.  jemalloc has a really discouraging amount of complexity that is directly a result of working around the performance overhead of MADV\_DONTNEED.
\end{quote}
 
 \item Mallocators want the kernel to notify them when memory is short.

 \item measure the value of the cache for purging

 \item turned off turboboost to measure (question: does this unfairly benefit jemalloc?)
   conclusion: no it affects jemalloc and supermalloc in about the same way.

\item Measure the value of the predo.  (Turn it off and see) (not much value)

\item try it on a bigger machine (it won't be haswell though...)

\item analysis of the 1k-aggregate data (measured on a haswell)

 jemalloc is slower.

 threadcache is slower (but not by a lot).  Maybe the complexity of the threadcache isn't worth it.

 Not really that much difference between predo and no-predo

 Not really that much difference between lock and rtm.

\item Need to measure it on a non-haswell type machine (and maybe a higher-core-count haswell machine)

\item can we really get away with lazy lock subscription?  Must review the code to be convinced.  Maybe have to do something else.

\item What about cache-index awarenes? 

 If the user asks for 1K aligned 1K, we should give it to them.

 Otherwise, we should give them 1K+64 bytes in a 16KB ``metapage'' (15 1K+64 objects just fit into 16K)
 
 When does it start?  Clearly there's no point until 128 bytes (which is 2 cache lines, but for objets of that size we aren't really worry about cache alignment.  192 is OK since things will appear variously.  At 256 maybe we should jump straight to 320?  Probalby not. 
   Let's start at the other end.  

   For huge objects, maybe we should and a random number of a page worth of cache lines (add 0 to 63 cache lines to the size, and return it aligned appropriately).

   For large objects, we keep the current large sizes, but unless the use asks for aligned data, we do the same thing: add 0 to 63 cache lines.

   Maybe add a new class of ``medium'' objects which are medium-page allocated (not within a page). 
    For example: add
      1024+64 bytes allocated in a 16KB metapage.
      2048+64 bytes allocated in a 16KB metapage (wastes 1600 bytes per metapage, or 10\%.  Cuuld make the metapage 64KB and with 31 objects per metapage waste 64 bytes at the end.
       (do we keep 1344, which wastes little but has fragmentation when the user asks for 1025 bytes?  Or do we got for 1280 (5/4 * 1024) and go to a metaage
          (or do we got to 5-page metapages, which wastes 2 pages at the end of each chunk since it's 512 pages per hugepage. Or we could allocate 5 hugepages and do the bookkeeping to avoid any wastage.  But we've already wasted 25\% because of our chunking so a few more doesn't matter, making the choice of a 64KB metapage with a waste of 256 bytes at the end.

     So here's a proposal, in addition to the current power-of-two sizes 256,512,1024,2048,4096,8192 (which are reserved for aligned allocations)
       * add 288 (if they ask for 225 to 288) (14 objects/page yielding 23.1\% internal fragmentation page-wide, 20.7\% for 8-byte data) (they get 256 only for alignment)
       * if they ask for 449-512 they get 576 (7 objects/page yielding 23.3\% internal fragmentation page wide, 22.1\% for 8-byte data)   (They get 512 only if they ask for aligne data)
       * add 960 (if they ask for 769-960) (4 objects/page isn't enough even though it yields only 24.9\% internal fragmentation page wide, because there aren't enough offsets
           so that's a problem
       * add 1088 with 16KB metapage (12\% fragmentation (1024 only for aligned, otherwise 961-1088 gets this.)
       * (1344 which we have incurs 20.2\% fragmentation on 1089-byte objects)
       
     Another proposal: Reserve the power-of-two bins for aligned requests.
       objects < 64 are done the way we do them now (within 4K pages)
       objects from 57 to 112 are done on 8K pages (using the bins for 72(new),80,96,112, (there will be lots of alignments))
       objects for 113 to 224 are done on 16K pages (using the bins for 144(new),160,192,224 (there will be be lots of alignments))
       objects for 225 to 448 are done on 32K pages (using the bins for 288(new),352,416,448,480 (all odd numbersa of 32)
       objects from 449 to 960 are done on 64K pages (is 32K enough) (using bins for 576,704 (instead of 768), 832(new), 960 (new) (all  odd number of 64s from now on)
       objects from 961 to 1088 are done on 64K pages

     So here's a proposal
        starting at 320-byte objects, all the objects will be a odd multiple of 64, and the number of objects per metapage will be <= 64 for speed of access
        320 on 16K pages (kind of a big gap to the next one)
        448 on 16K pages
        576 on 32K pages
        704 on 32K pages   (start skipping by 256)
        960 on 32K pages
        1216 on 64K pages 
        1472 on 64K pages  (start skipping by 512)
        1984 on 64K pages
        2496 on 128K pages
        3008 on 128K pages (start skipping by 1024)
        4032 on 128K pages
        5056 on 256K pages
        6080 on 256K pages (start skipping by 2048)
        8128 on 256K pages
        10176 on 512K pages
        12224 on 512K pages
        after that it's page aligned: and a random number of cache lines to an object, allocate pages to fit, and return the offseat
         e.g., ask for 12225, add up to 63 cache lines.  If you actually add 63, you need 16257 which fits in 4 pages (16384), so allocate 4 pages.
          If you happened to add 0 you can do it with 3 pages.  So usually you are using 4 pages to represent 3 pages.  
        
      then after that it's page aligned but with a random 

        1728 on 64K pages (start skipping by 512)
        2240 on 128K pages

        832 on 32K pages   (start skipping by 256)
        1088 on 64K pages
        1344 on 64K pages
        1600 on 64K pages  (start skipping by 512) 
        1856 on 64K pages 
        2368

\item What about NUMA friendly?  Should I care?

\item Debuging: INsert this
    if (_xtest()) _xabort(10);
to find out where the transaction is aborting.

\end{enumerate}
