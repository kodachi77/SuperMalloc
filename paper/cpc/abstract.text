SuperMalloc: A SuperFast Multithreaded malloc() Designed for X86 Transactional Memory

SuperMalloc is an implementation of malloc(3) that uses x86 Transactional Memory instructions.  On Haswell systems with Transactional Memory, SuperMalloc outperforms JEmalloc and Hoard by more than a factor of two on difficult memory-allocation workloads, typically with a substantially smaller footprint.  (A ``difficult workload'' is exemplified by one in which K producer threads allocate objects while K consumer threads deallocate them, all as quickly as possible.)

One early design decision in any allocator is how small objects will be managed.  DLmalloc, the allocator shipped with Linux, employs boundary tags around each object, which contributes to space overhead, and uses a first-fit heuristic for allocating space.  In contrast, more modern allocators, such as Hoard and JEmalloc, allocate large chunks (typically several megabytes), each of which contain a single size ``class'' of data.  These allocators can use use a bitmap for space allocation.  SuperMalloc uses the single-class-per-large-chunk approach of Hoard and JEmalloc.  The system must be able to determine the size of an object from its pointer.  To do so, previous allocators typically use a tree structures to look up the class of a chunk.  In contrast, SuperMalloc uses an simple array.  This chunk array consumes 512MiB of virtual address space, but because chunks are typically contiguously allocated, only the array consumes only a few pages of physical address space.  By using a simple array instead of a tree, fewer instructions and cache misses are needed to look up the chunk information.

SuperMalloc uses simple data structures to try to maximize the odds that hardware transactions succeed. For example, the SuperMalloc uses a priority heap to allocate objects out of the fullest page.  The heap takes advantage of the fact that for each class, there are only a relatively small number of possible page-fullness values.  For example, for 8-byte objects, there are only 512 objects in a page, and so instead of using a general heap, SuperMalloc uses an array of 513 lists, the $i$th list containing a list of pages with $i$ free slots.

SuperMalloc uses a per-CPU cache and a per-thread cache.  A per-thread cache of objects reduces the overhead of allocating and freeing objects because some objects do not need to perform any mutual exclusion.  It turns out that most of the cost of updating a global data structure is due to cache misses, not the locking itself, however.  On Haswell, an unlocked update to an uncontended cache line costs 3--5ns, whereas acquiring a lock and modifying uncontended variable costs 80ns.  Acquiring an uncontended lock and updating an uncontended page costs only about 18ns.  (On a multisocket Sandy Bridge processor, the difference is even more striking: 3ns uncontended unlocked, 26ns uncontended locked, and 460ns contended locked.)  Accordingly, SuperMalloc uses a relatively small per-thread cache (containing only a few objects of each size), and uses a per-CPU cache (a cache per hardware thread).  The per-CPU cache contains only one L3-cache worth of objects for each size class, since we assume that the application will actually store data into allocated objects.  If the objects in the per-CPU cache don't fit in the L3 cache, then filling the objects will cause cache misses anyway, so it does not matter whether allocating the objects causes a few cache misses.

To further improve the odds of transactions committing, SuperMalloc tries to prefetch into cache all the data of the transaction. Prefetching data appears to improve performance by about 5%.

SuperMalloc appears to enjoy a substantially smaller footprint than the other allocators for two reasons.  (1) SuperMalloc adopts Hoard's allocate-in-fullest-page heuristic rather than JEmalloc's approach of allocating the object with the lowest address.  (2) SuperMalloc's caches are smaller than Hoard's or JEmallocs, mostly because the per-thread cache is extremely small, and in many applications there are far more threads than there are CPU's.

SuperMalloc is currently implemented, and we are assembling and running the allocation benchmarks mentioned in other allocation papers.  We plan to release the software under the Apache 2.0 license, and the assembled benchmarks under an appropriate mix of licenses.
